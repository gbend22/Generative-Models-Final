# NCSN Base Configuration for CIFAR-10
# configs/ncsn_base.yaml

# Model Architecture
in_channels: 3
base_channels: 128
num_noise_levels: 10
sigma_begin: 1.0
sigma_end: 0.01

# Training
epochs: 200
batch_size: 128
lr: 0.0001
lr_min: 0.000001
beta1: 0.9
beta2: 0.999
weight_decay: 0.0
grad_clip: 1.0

# Loss
use_annealed_loss: true
loss_weighting: 'exponential'  # 'uniform', 'exponential', 'inverse'

# EMA (Exponential Moving Average)
use_ema: true
ema_decay: 0.999

# Sampling
sample_steps: 100
sample_step_lr: 0.00002

# Logging
project_name: 'cifar10-ncsn'
run_name: 'ncsn-baseline-refine128'
log_interval: 100
sample_interval: 10
save_interval: 20
checkpoint_dir: 'checkpoints'

# Data
num_workers: 4
data_dir: './data'

# Experiment-specific settings
experiment_notes: |
  Baseline NCSN with RefineNet backbone.
  - 128 base channels
  - 10 noise levels (geometric from 1.0 to 0.01)
  - Annealed Langevin dynamics with 100 steps per level
  - Exponential weighting for loss annealing